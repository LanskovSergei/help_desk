import os
from llama_index import StorageContext, load_index_from_storage
from llama_index.llms import OpenAI
from llama_index.embeddings import OpenAIEmbedding
from llama_index import ServiceContext

# ==== –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ====
os.environ["OPENAI_API_KEY"] = ""

# ==== –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–Ω–¥–µ–∫—Å –∏–∑ ./storage ====
storage_context = StorageContext.from_defaults(persist_dir="./storage")
index = load_index_from_storage(storage_context)

# ==== –°–æ–∑–¥–∞—ë–º –¥–≤–∏–∂–æ–∫ –∑–∞–ø—Ä–æ—Å–æ–≤ ====
service_context = ServiceContext.from_defaults(
    llm=OpenAI(temperature=0),
    embed_model=OpenAIEmbedding()
)
query_engine = index.as_query_engine(service_context=service_context)

# ==== –¶–∏–∫–ª –≤–æ–ø—Ä–æ—Å–æ–≤ ====
print("üß† –í–≤–µ–¥–∏—Ç–µ –≤–æ–ø—Ä–æ—Å (–∏–ª–∏ 'exit' –¥–ª—è –≤—ã—Ö–æ–¥–∞):")
while True:
    user_input = input("‚ùì –í–æ–ø—Ä–æ—Å: ").strip()
    if user_input.lower() in ["exit", "quit"]:
        break

    try:
        response = query_engine.query(user_input)
        print("\nüí¨ –û—Ç–≤–µ—Ç:\n", response, "\n")
    except Exception as e:
        print("‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞:", e)
