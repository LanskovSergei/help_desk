import os
from fastapi import FastAPI
from pydantic import BaseModel
from typing import Optional
import uvicorn
from datetime import datetime

from llama_index.core import load_index_from_storage, Settings
from llama_index.core.storage.storage_context import StorageContext
from llama_index.llms.openai import OpenAI
from llama_index.embeddings.openai import OpenAIEmbedding

# ==== Config ====
os.environ["OPENAI_API_KEY"] = "sk-proj-..."  # –ó–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ –∞–∫—Ç—É–∞–ª—å–Ω—ã–π –∫–ª—é—á
ALLOWED_USER_IDS = {"123456789"}  # –†–∞–∑—Ä–µ—à—ë–Ω–Ω—ã–µ user_id

Settings.llm = OpenAI(model="gpt-3.5-turbo", temperature=0)
Settings.embed_model = OpenAIEmbedding(model="text-embedding-3-small")

# ==== Load Index ====
storage_context = StorageContext.from_defaults(persist_dir="./storage")
index = load_index_from_storage(storage_context)
query_engine = index.as_query_engine(similarity_top_k=3)

# ==== FastAPI App ====
app = FastAPI()

# ==== Request/Response Models ====
class QuestionRequest(BaseModel):
    question: str
    user_id: Optional[str] = None

class AIResponse(BaseModel):
    answer: str
    article_url: Optional[str] = None
    has_answer: bool

# ==== Main Endpoint ====
@app.post("/ask", response_model=AIResponse)
async def ask_ai(request: QuestionRequest):
    # Log request
    log_line = f"{datetime.now().isoformat()} | USER_ID: {request.user_id} | Q: {request.question}\n"
    with open("requests.log", "a") as f:
        f.write(log_line)

    # Check user access
    if request.user_id not in ALLOWED_USER_IDS:
        return AIResponse(
            answer="Access denied. You are not authorized to use this service.",
            article_url=None,
            has_answer=False
        )

    try:
        response = query_engine.query(request.question)

        # üõ°Ô∏è –ß—ë—Ç–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –µ—Å—Ç—å –ª–∏ —Ö–æ—Ç—å –æ–¥–∏–Ω —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫
        if not response.source_nodes:
            return AIResponse(
                answer="Information not found. Would you like to talk to an operator?",
                article_url=None,
                has_answer=False
            )

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –∏—Å—Ç–æ—á–Ω–∏–∫ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç
        first_node = response.source_nodes[0]
        answer_text = str(response).strip()
        if not answer_text:
            return AIResponse(
                answer="Information not found. Would you like to talk to an operator?",
                article_url=None,
                has_answer=False
            )

        article_url = first_node.node.metadata.get("url")

        return AIResponse(
            answer=answer_text,
            article_url=article_url,
            has_answer=True
        )

    except Exception:
        return AIResponse(
            answer="Information not found. Would you like to talk to an operator?",
            article_url=None,
            has_answer=False
        )

# ==== Server Runner ====
if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)
